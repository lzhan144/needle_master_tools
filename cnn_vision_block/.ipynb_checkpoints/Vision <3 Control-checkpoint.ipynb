{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Visuomotor Control \n",
    "Use standard control to move the needle to the targets. <br> \n",
    "predict the needle and gate position from the image or use the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "* pytorch_datasets for Dataset class, DataLoader\n",
    "* numpy for math \n",
    "* torch for deep learning library\n",
    "* torchvision for deep learning vision library \n",
    "* multiprocessing to run on multiple cpus (if applicable)\n",
    "* random to select random trials/frames in _get__item_, and to make random datasplits\n",
    "* matplotlib for displaying image frames\n",
    "* pdb (debugging)\n",
    "* controller: the PIDcontroller class (we implemented this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/molly/workspace/Utils/pytorch_datasets/')\n",
    "sys.path.insert(0, '/home/molly/workspace/Surgical_Automation/src/needle_master_tools/scripts/')\n",
    "\n",
    "import random \n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "from pdb import set_trace as woah\n",
    "from controller import PIDcontroller\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import pytorch_datasets\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to set up the environment. Choose if the deep learning will run on the CPU or GPU. Initialize the torch random seed, and if using a GPU the GPU random seed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(random.randint(1, 10000))\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if(DEVICE == \"cuda:0\"):\n",
    "    torch.cuda.manual_seed(random.randint(1, 10000))\n",
    "    # Disable nondeterministic ops (not sure if critical but better safe than sorry)\n",
    "    torch.backends.cudnn.enabled = False  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook uses the Pytorch Datasets wrapper to write a data loader for the NeedleMaster dataset. \n",
    "\n",
    "* __NeedleMaster__ is an Android game developped by Chris Paxton (https://github.com/cpaxton/needle_master_tools.) Images from recorded demonstrations were rendered to create a toy dataset with images, needle poses, and user actions. This dataset is currently on a local directory. For information contact molly@jhu.edu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENVIRONMENT = None # \n",
    "nm = pytorch_datasets.NeedleFrames('/home/molly/workspace/Surgical_Automation/experiments/needle_master_tools/', \\\n",
    "                                  environment=ENVIRONMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model \n",
    "Model trained on all levels except level 14 (Mountain). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Contol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_constraints = [10, np.pi/10]           # constraints on allowable motion\n",
    "parameters         = [0.1,0.0009]             # proportional control parameters --- these have been hand tuned\n",
    "pid                = PIDcontroller(params=parameters, bounds=action_constraints)\n",
    "\n",
    "save_images        = False\n",
    "environment        = nm.Environment(env_path, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "environment.render(save_image=save_images)\n",
    "\n",
    "while(not done):\n",
    "    if(environment.next_gate is not None):\n",
    "        next_gate = environment.gates[environment.next_gate]\n",
    "    else:\n",
    "        next_gate = None\n",
    "\n",
    "    action  = pid.step([environment.needle.x, environment.needle.y, environment.needle.w], next_gate)\n",
    "    _, _, done   = environment.step(action, 'play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"________________________\")\n",
    "environment.score(True)\n",
    "print(\"________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
